{
    "version": "v1.0",
    "author": "Andrew Shaw, Yaroslav Bulatov, Jeremy Howard",
    "authorEmail": "andrew.t.shaw@gmail.com",
    "framework": "ncluster / Pytorch 0.5.0a0+0e8088d",
    "codeURL": "https://github.com/diux-dev/imagenet18/blob/59a8f25171fb8cede51db9187a32fc8f802384a0/training/train_imagenet_nv.py",
    "model": "Resnet 50",
    "hardware": "32 * V100 (4 machines - AWS p3.16xlarge)",
    "costPerHour": 97.92,
    "timestamp": "2018-09-07",
    "usedBlacklist": true,
    "misc": {
        "model implementation": "https://github.com/diux-dev/imagenet18/blob/24d21e24393046164fcc6d1ea3be18d2831ff9e6/training/resnet.py",
        "training schedule": "https://github.com/diux-dev/imagenet18/blob/4edeea10854f8913f6bf3298c1eec72bf59d0594/train.py#L44",
        "backend": "NCCL 2.2.13+cuda9.2",
        "optimizer": "SGD with Momentum",
        "train.py args": "https://github.com/diux-dev/imagenet18/blob/24d21e24393046164fcc6d1ea3be18d2831ff9e6/train.py#L174",
        "misc": "Tricks - http://www.fast.ai/2018/08/10/fastai-diu-imagenet/. Progressive resizing, variable batch size, scaling learning rate to batch size, rectangular image validation, one-cycleish learning schedule, removing batch-norm from weight decay",
        "learning_rate_misc": "Warmup 14 epochs - Increase learning rate to 2x and then back down. Divide learning rate by 10 every 6 epochs after (with linear smoothing). Learning rate is adjusted to scale with batch size",
        "momentum": 0.9,
        "weightDecay": 0.0001,
        "batchSize": [
          {"batch_size": 8192, "epochs": 6},
          {"batch_size": 16384, "epochs": 7},
          {"batch_size": 7168, "epochs": 15},
          {"batch_size": 8192, "epochs": 2}
        ],
        "imageSize": [
            {"image_size": 128, "epochs": 13},
            {"image_size": 224, "epochs": 15},
            {"image_size": 288, "epochs": 2}
        ],
        "schedule": [
          {"learning_rate": [1,2], "epochs": 6, "linear": true},
          {"learning_rate": 2, "epochs": 5},
          {"learning_rate": [4,2], "epochs": 2, "linear": true},
          {"learning_rate": 1.75, "epochs": 3},
          {"learning_rate": [1.75,0.175], "epochs": 7, "linear": true},
          {"learning_rate": [0.175,0.0175], "epochs": 4, "linear": true},
          {"learning_rate": [0.01,0.001], "epochs": 2, "linear": true}
        ]
    }
}
